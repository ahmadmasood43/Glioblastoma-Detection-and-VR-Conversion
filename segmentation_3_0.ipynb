{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadmasood43/Glioblastoma-Detection-and-VR-Conversion/blob/main/segmentation_3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXG6LYaZFaB5",
        "outputId": "2300b2f5-439b-4398-f3ee-f7ea29ca54a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WCDUXV8zFveO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, MaxPooling2D, concatenate\n",
        "from skimage.draw import polygon2mask, ellipse_perimeter, rectangle_perimeter, circle_perimeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "l1YZzuYsGA7o",
        "outputId": "2e926666-04b9-4a0a-8a49-fc38ed30a374"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-810d962eeb17>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Read the image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Extract region shape attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imread' is not defined"
          ]
        }
      ],
      "source": [
        "from skimage.draw import polygon, circle_perimeter, ellipse_perimeter, rectangle_perimeter\n",
        "\n",
        "# Read the CSV file\n",
        "import pandas as pd\n",
        "# Load the annotation CSV file\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/new_fyp_dataset_folder/annotation_fyp_all_yes.csv')\n",
        "\n",
        "# Create lists to store image paths and corresponding masks\n",
        "image_paths = []\n",
        "masks = []\n",
        "\n",
        "# Iterate over each row in the CSV file\n",
        "for index, row in df.iterrows():\n",
        "    # Read the image file\n",
        "    filename = row['filename']\n",
        "    image = imread(filename)\n",
        "\n",
        "    # Extract region shape attributes\n",
        "    region_shape = eval(row['region_shape_attributes'])\n",
        "    shape_name = region_shape['name']\n",
        "    shape_attributes = region_shape['attributes']\n",
        "\n",
        "    if shape_name == 'polygon':\n",
        "        # Extract polygon coordinates\n",
        "        polygon_x = region_shape['all_points_x']\n",
        "        polygon_y = region_shape['all_points_y']\n",
        "\n",
        "        # Create a binary mask from the polygon coordinates\n",
        "        mask = np.zeros_like(image[:, :, 0])\n",
        "        mask[polygon_y, polygon_x] = 1\n",
        "    elif shape_name == 'circle':\n",
        "        # Extract circle attributes\n",
        "        center_x = region_shape['cx']\n",
        "        center_y = region_shape['cy']\n",
        "        radius = region_shape['r']\n",
        "        \n",
        "        # Create a binary mask for the circle\n",
        "        mask = np.zeros_like(image[:, :, 0])\n",
        "        rr, cc = circle_perimeter(int(center_y), int(center_x), int(radius), shape=mask.shape)\n",
        "        mask[rr, cc] = 1\n",
        "    elif shape_name == 'ellipse':\n",
        "        # Extract ellipse attributes\n",
        "        center_x = region_shape['cx']\n",
        "        center_y = region_shape['cy']\n",
        "        radius_x = region_shape['rx']\n",
        "        radius_y = region_shape['ry']\n",
        "        rotation = region_shape['theta']\n",
        "        \n",
        "        # Create a binary mask for the ellipse\n",
        "        mask = np.zeros_like(image[:, :, 0])\n",
        "        rr, cc = ellipse_perimeter(int(center_y), int(center_x), int(radius_y), int(radius_x), orientation=np.deg2rad(rotation), shape=mask.shape)\n",
        "        mask[rr, cc] = 1\n",
        "    elif shape_name == 'rectangle':\n",
        "        # Extract rectangle attributes\n",
        "        x = region_shape['x']\n",
        "        y = region_shape['y']\n",
        "        width = region_shape['width']\n",
        "        height = region_shape['height']\n",
        "        \n",
        "        # Create a binary mask for the rectangle\n",
        "        mask = np.zeros_like(image[:, :, 0])\n",
        "        rr, cc = rectangle_perimeter((int(y), int(x)), extent=(int(height), int(width)), shape=mask.shape)\n",
        "        mask[rr, cc] = 1\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported region shape: {shape_name}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bVoTEJzEs9s"
      },
      "outputs": [],
      "source": [
        "# Define a custom data generator for loading images and masks\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, image_paths, masks, batch_size=32, image_size=(256, 256)):\n",
        "        self.image_paths = image_paths\n",
        "        self.masks = masks\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_image_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_masks = self.masks[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        for image_path in batch_image_paths:\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.resize(image, self.image_size)\n",
        "            batch_images.append(image)\n",
        "\n",
        "        batch_images = np.array(batch_images) / 255.0\n",
        "        batch_masks = np.array(batch_masks) / 255.0\n",
        "        batch_masks = np.expand_dims(batch_masks, axis=-1)\n",
        "\n",
        "        return batch_images, batch_masks\n",
        "\n",
        "# Create the U-Net model architecture\n",
        "def unet(input_size=(256, 256, 3)):\n",
        "    inputs = keras.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bridge\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Decoder\n",
        "    up5 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create the training and validation data generators\n",
        "train_generator = DataGenerator(image_paths[:800], masks[:800])\n",
        "val_generator = DataGenerator(image_paths[800:], masks[800:])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('tumor_segmentation_model.h5')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2E/1c0RZUO4S6EoQWKNhC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}