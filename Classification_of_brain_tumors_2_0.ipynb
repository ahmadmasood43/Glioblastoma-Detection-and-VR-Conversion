{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcNhRnU4GHbsWfyL/BqTPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadmasood43/Glioblastoma-Detection-and-VR-Conversion/blob/main/Classification_of_brain_tumors_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "I6hgnWDeOFXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xxy4mB92Gh4v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import google drive"
      ],
      "metadata": {
        "id": "HwYi716HOKrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDUpu7K3Gz38",
        "outputId": "1dee07f9-1363-40bc-bbff-81d45157f09f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess data"
      ],
      "metadata": {
        "id": "nsbFlFWHOPlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Load tumor CSV file\n",
        "tumor_data = pd.read_csv('/content/gdrive/MyDrive/new_fyp_dataset_folder/annotation_fyp.csv')\n",
        "\n",
        "# Load non-tumor CSV file\n",
        "non_tumor_data = pd.read_csv('/content/gdrive/MyDrive/new_fyp_dataset_folder/annotation_fyp_no.csv')\n",
        "\n",
        "# Preprocess tumor data\n",
        "tumor_image_dir = '/content/gdrive/MyDrive/new_fyp_dataset_folder/yes'  # Directory containing the tumor images\n",
        "tumor_image_paths = []\n",
        "tumor_labels = []\n",
        "\n",
        "for _, row in tumor_data.iterrows():\n",
        "    image_path = os.path.join(tumor_image_dir, row['filename'])\n",
        "    tumor_image_paths.append(image_path)\n",
        "    tumor_labels.append(1)  # Tumor label\n",
        "\n",
        "# Preprocess non-tumor data\n",
        "non_tumor_image_dir = '/content/gdrive/MyDrive/new_fyp_dataset_folder/no'  # Directory containing the non-tumor images\n",
        "non_tumor_image_paths = []\n",
        "non_tumor_labels = []\n",
        "\n",
        "for _, row in non_tumor_data.iterrows():\n",
        "    image_path = os.path.join(non_tumor_image_dir, row['filename'])\n",
        "    non_tumor_image_paths.append(image_path)\n",
        "    non_tumor_labels.append(0)  # Non-tumor label\n",
        "\n",
        "# Combine tumor and non-tumor data\n",
        "image_paths = tumor_image_paths + non_tumor_image_paths\n",
        "labels = tumor_labels + non_tumor_labels\n",
        "\n",
        "# Create a new DataFrame with image paths and labels\n",
        "preprocessed_data = pd.DataFrame({'image_paths': image_paths, 'labels': labels})\n",
        "\n",
        "# Convert labels to strings\n",
        "preprocessed_data['labels'] = preprocessed_data['labels'].astype(str)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data, valid_data = train_test_split(preprocessed_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_data,\n",
        "    x_col='image_paths',\n",
        "    y_col='labels',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=valid_data,\n",
        "    x_col='image_paths',\n",
        "    y_col='labels',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGYjVH5pGud_",
        "outputId": "3c1ad6b7-ea34-411a-d441-93bb1d639142"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 683 validated image filenames belonging to 2 classes.\n",
            "Found 171 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load VGG16 model"
      ],
      "metadata": {
        "id": "nFypREr2OoBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all layers except the last 2\n",
        "for layer in base_model.layers[:-2]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "fiVhI5izKsho"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n"
      ],
      "metadata": {
        "id": "LKQd4LzkLQi0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Classifier"
      ],
      "metadata": {
        "id": "M9lyO68wO8-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=len(valid_generator)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pznaI4QVLTd1",
        "outputId": "84250657-b4c3-4de4-8e92-343c320db518"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 590s 26s/step - loss: 0.5536 - accuracy: 0.7145 - val_loss: 0.3461 - val_accuracy: 0.8070\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 623s 28s/step - loss: 0.3307 - accuracy: 0.8463 - val_loss: 0.2792 - val_accuracy: 0.8421\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 608s 28s/step - loss: 0.2430 - accuracy: 0.8990 - val_loss: 0.3036 - val_accuracy: 0.8655\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 576s 26s/step - loss: 0.1929 - accuracy: 0.9209 - val_loss: 0.2309 - val_accuracy: 0.8830\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 606s 28s/step - loss: 0.1700 - accuracy: 0.9414 - val_loss: 0.1688 - val_accuracy: 0.9532\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 572s 26s/step - loss: 0.1345 - accuracy: 0.9575 - val_loss: 0.1741 - val_accuracy: 0.9006\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 605s 28s/step - loss: 0.1135 - accuracy: 0.9561 - val_loss: 0.1271 - val_accuracy: 0.9591\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 605s 28s/step - loss: 0.0851 - accuracy: 0.9693 - val_loss: 0.1316 - val_accuracy: 0.9591\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 606s 28s/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.1314 - val_accuracy: 0.9591\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 604s 28s/step - loss: 0.0876 - accuracy: 0.9693 - val_loss: 0.1949 - val_accuracy: 0.9357\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f96f7705240>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Dataset"
      ],
      "metadata": {
        "id": "CtDNGlKzjafo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Path to the folder containing the images for testing\n",
        "test_folder = '/content/gdrive/MyDrive/new_fyp_dataset_folder/testing'\n",
        "\n",
        "# Get the list of image filenames in the test folder\n",
        "image_filenames = os.listdir(test_folder)\n",
        "\n",
        "# Define the input size expected by the model\n",
        "image_width = 224\n",
        "image_height = 224\n",
        "\n",
        "# Define the selected threshold value\n",
        "threshold = 0.5\n",
        "\n",
        "# Assuming you have the model object available after training\n",
        "model = model # Replace with the actual name of your trained model object\n",
        "\n",
        "# Iterate over the images and perform predictions\n",
        "for image_filename in image_filenames:\n",
        "    image_path = os.path.join(test_folder, image_filename)\n",
        "    \n",
        "    # Load the image\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary\n",
        "        image = cv2.resize(image, (image_width, image_height))  # Resize the image to match the input size of your model\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image '{image_filename}': {str(e)}\")\n",
        "        continue\n",
        "    \n",
        "    # Preprocess the image\n",
        "    try:\n",
        "        # Perform any additional preprocessing steps here if required\n",
        "        \n",
        "        # Normalize the image pixel values to [0, 1]\n",
        "        image = image / 255.0\n",
        "        \n",
        "        # Reshape the image to match the input shape expected by the model\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing image '{image_filename}': {str(e)}\")\n",
        "        continue\n",
        "    \n",
        "    # Perform prediction using the model\n",
        "    try:\n",
        "        predictions = model.predict(image)\n",
        "        \n",
        "        # Get the predicted class (assuming single-label classification)\n",
        "        predicted_class = np.argmax(predictions, axis=1).item()\n",
        "        \n",
        "        # Determine the prediction based on the selected threshold\n",
        "        if predictions[0][predicted_class] >= threshold:\n",
        "            prediction_result = True\n",
        "        else:\n",
        "            prediction_result = False\n",
        "        \n",
        "        # Print the prediction result or perform any further processing\n",
        "        \n",
        "        # Example: Printing the filename and prediction result\n",
        "        print(f\"Image: {image_filename}, Prediction Result: {prediction_result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting image '{image_filename}': {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MskgWUQ9jVoc",
        "outputId": "162d8a13-f429-4eb1-c076-41c2390dbddf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-24.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-22.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-23.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 715ms/step\n",
            "Image: 1-21.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Image: 1-25.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "Image: 1-26.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Image: 1-27.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Image: 1-04.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "Image: 1-02.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 552ms/step\n",
            "Image: 1-06.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Image: 1-28.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Image: 1-12.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "Image: 1-03.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Image: 1-01.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "Image: 1-05.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Image: 1-08.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Image: 1-07.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 558ms/step\n",
            "Image: 1-09.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 712ms/step\n",
            "Image: 1-14.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-15.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-10.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: 1-16.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 670ms/step\n",
            "Image: 1-17.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Image: 1-18.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "Image: 1-13.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Image: 1-19.png, Prediction Result: True\n",
            "1/1 [==============================] - 1s 552ms/step\n",
            "Image: 1-11.png, Prediction Result: False\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "Image: 1-20.png, Prediction Result: True\n"
          ]
        }
      ]
    }
  ]
}